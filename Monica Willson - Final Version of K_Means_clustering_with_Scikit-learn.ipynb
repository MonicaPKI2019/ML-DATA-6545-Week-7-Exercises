{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.5"},"colab":{"provenance":[{"file_id":"1Xf_zM0PeXJW3JcBMo4za-FYO7A2BMt47","timestamp":1605672048814}]}},"cells":[{"cell_type":"markdown","metadata":{"id":"PFqlDhb63GjL"},"source":["# K-Means Clustering in Python with scikit-learn\n","Learn about the inner workings of the K-Means clustering algorithm with an interesting case study.\n","\n","In Machine Learning, the types of Learning can broadly be classified into three types: 1. Supervised Learning, 2. Unsupervised Learning and 3. Semi-supervised Learning. Algorithms belonging to the family of Unsupervised Learning have no variable to predict tied to the data. Instead of having an output, the data only has an input which would be multiple variables that describe the data. This is where clustering comes in.\n","\n","Clustering is the task of grouping together a set of objects in a way that objects in the same cluster are more similar to each other than to objects in other clusters. Similarity is a metric that reflects the strength of relationship between two data objects. Clustering is mainly used for exploratory data mining. It has manifold usage in many fields such as machine learning, pattern recognition, image analysis, information retrieval, bio-informatics, data compression, and computer graphics.\n","\n","However, this post tries to unravel the inner workings of K-Means, a very popular clustering technique. There's also a very good [DataCamp post](https://www.datacamp.com/community/tutorials/k-means-clustering-r) on K-Means, which explains the types of clustering (hard and soft clustering), types of clustering methods (connectivity, centroid, distribution and density) with a case study. The algorithm will help you to tackle unlabeled datasets (i.e. the datasets that do not have any class-labels) and draw your own inferences from them with ease.\n","\n","K-Means falls under the category of centroid-based clustering. A centroid is a data point (imaginary or real) at the center of a cluster. In centroid-based clustering, clusters are represented by a central vector or a centroid. This centroid might not necessarily be a member of the dataset. Centroid-based clustering is an iterative algorithm in which the notion of similarity is derived by how close a data point is to the centroid of the cluster.\n","\n","In this post, you will learn about:\n","- The inner workings of the K-Means algorithm\n","- A simple case study in Python\n","- The disadvantages of K-Means"]},{"cell_type":"markdown","metadata":{"id":"m8R0ztnA3GjM"},"source":["## The inner workings of the K-Means clustering algorithm:\n","To do this, you will need a sample dataset (training set):\n","\n","|Objects|X|Y|Z|\n","|-------|-|-|-|\n","|OB-1   |1|4|1|\n","|OB-2   |1|2|2|\n","|OB-3   |1|4|2|\n","|OB-4   |2|1|2|\n","|OB-5   |1|1|1|\n","|OB-6   |2|4|2|\n","|OB-7   |1|1|2|\n","|OB-8   |2|1|1|\n","\n","The sample dataset contains 8 objects with their X, Y and Z coordinates. Your task is to cluster these objects into two clusters (here you define the value of K (of K-Means) in essence to be 2).\n","\n","So, the algorithm works by:\n","\n","- Taking any two centroids or data points (as you took 2 as K hence the number of centroids also 2) in its account initially.\n","- After choosing the centroids, (say C1 and C2) the data points (coordinates here) are assigned to any of the Clusters (let’s take centroids = clusters for the time being) depending upon the distance between them and the centroids.\n","- Assume that the algorithm chose OB-2 (1,2,2) and OB-6 (2,4,2) as centroids and cluster 1 and cluster 2 as well.\n","- For measuring the distances, you take the following distance measurement function (also termed as similarity measurement function):\n","\n","$$ d=|x2–x1|+|y2–y1|+|z2–z1| $$\n","        \n","This is also known as the Taxicab distance or Manhattan distance, where d is distance measurement between two objects, (x1,y1,z1) and (x2,y2,z2) are the X, Y and Z coordinates of any two objects taken for distance measurement.\n","\n","Feel free to check out other distance measurement functions like Euclidean Distance, Cosine Distance etc.\n","\n","The following table shows the calculation of distances (using the above distance measurement function) between the objects and centroids (OB-2 and OB-6): \n","\n","|Objects|X|Y|Z|Distance from C1(1,2,2)|Distance from C2(2,4,2)|\n","|-------|-|-|-|-----------------------|-----------------------|\n","|OB-1\t|1|4|1|3\t                  |2|\n","|OB-2\t|1|2|2|0\t                  |3|\n","|OB-3\t|1|4|2|2\t                  |1|\n","|OB-4\t|2|1|2|2\t                  |3|\n","|OB-5\t|1|1|1|2\t                  |5|\n","|OB-6\t|2|4|2|3\t                  |0|\n","|OB-7\t|1|1|2|1\t                  |4|\n","|OB-8\t|2|1|1|3                \t  |4|\n","\n","The objects are clustered based on their distances between the centroids. An object which has a shorter distance between a centroid (say C1) than the other centroid (say C2) will fall into the cluster of C1. After the initial pass of clustering, the clustered objects will look something like the following:\n","\n","|Cluster 1|Cluster 2|\n","|---------|---------|\n","|OB-2     |OB-1|\n","|OB-4     |OB-3|\n","|OB-5     |OB-6|\n","|OB-7     | |\n","|OB-8     | |\n","\n","Now the algorithm will continue updating cluster centroids (i.e the coordinates) until they cannot be updated anymore (more on when it cannot be updated later). The updation takes place in the following manner:\n","\n","\\begin{equation*}\n","(\\frac{\\sum_{i-1}^n x_i}{n}),\n","(\\frac{\\sum_{i-1}^n y_i}{n}),\n","(\\frac{\\sum_{i-1}^n z_i}{n})\n","\\end{equation*}\n","\n","where $n$ = number of objects belonging to that particular cluster.\n","\n","So, following this rule the updated cluster 1 will be ((1+2+1+1+2)/5, (2+1+1+1+1)/5,(2+2+1+2+1)/5) = (1.4,1.2,1.6). And for cluster 2 it will be ((1+1+2)/3, (4+4+4)/3, (1+2+2)/3) = (1.33, 4, 1.66).\n","\n","After this, the algorithm again starts finding the distances between the data points and newly derived cluster centroids. So the new distances will be like following: \n","\n","|Objects|X|Y|Z|Distance from C1(1.4,1.2,1.6)|Distance from C2(1.33,4,1.66)|\n","|-------|-|-|-|-----------------------|-----------------------|\n","|OB-1\t|1|4|1|3.8\t                  |1|\n","|OB-2\t|1|2|2|1.6\t                  |2.66|\n","|OB-3\t|1|4|2|3.6\t                  |0.66|\n","|OB-4\t|2|1|2|1.2\t                  |4|\n","|OB-5\t|1|1|1|1.2\t                  |4|\n","|OB-6\t|2|4|2|3.8\t                  |1|\n","|OB-7\t|1|1|2|1\t                  |3.66|\n","|OB-8\t|2|1|1|1.4                \t  |4.33|\n","\n","The new assignments of the objects with respect to the updated clusters will be: \n","\n","|Cluster 1|Cluster 2|\n","|---------|---------|\n","|OB-2     |OB-1|\n","|OB-4     |OB-3|\n","|OB-5     |OB-6|\n","|OB-7     | |\n","|OB-8     | |\n","\n","This is where the algorithm no longer updates the centroids. Because there is no change in the current cluster formation, it is the same as the previous formation.\n","\n","Now when, you are done with the cluster formation with K-Means you may apply it to some data the algorithm has not seen before (what you call a Test set). Let's generate that: \n","\n","|Objects|X|Y|Z|\n","|-------|-|-|-|\n","|OB-1   |2|4|1|\n","|OB-2   |2|2|2|\n","|OB-3   |1|2|1|\n","|OB-4   |2|2|1|\n","\n","After applying K-means on the above dataset, the final clusters will be:\n","\n","|Cluster 1|Cluster 2|\n","|---------|---------|\n","|OB-2     |OB-1|\n","|OB-3     | |\n","|OB-4     | |\n","\n","Any application of an algorithm is incomplete if one is not sure about its performance. Now, in order to know how well the K-Means algorithm is performing there are certain metrics to consider. Some of these metrics are:\n","\n","- Adjusted rand index\n","- Mutual information based scoring\n","- Homogeneity, completeness and v-measure\n","\n","Now that you have got familiar with the inner mechanics of K-Means let's see K-Means live in action."]},{"cell_type":"markdown","metadata":{"id":"KhBZVvYq3GjN"},"source":["## A simple case study of K-Means in Python:\n","For the implementation part, you will be using the Titanic dataset (available here). Before proceeding with it, I would like to discuss some facts about the data itself. The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n","\n","One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n","\n","Now, talking about the dataset, the training set contains several records about the passengers of Titanic (hence the name of the dataset). It has 12 features capturing information about `passenger_class`, `port_of_Embarkation`, `passenger_fare` etc. The dataset's label is survival which denotes the survivial status of a particular passenger. Your task is to cluster the records into two i.e. the ones who survived and the ones who did not.\n","\n","You might be thinking that since it is a labeled dataset, how could it be used for a clustering task? You just have to drop the 'survival' column from the dataset and make it unlabeled. It's the task of K-Means to cluster the records of the datasets if they survived or not.\n","\n","For this tutorial, you will need the following Python packages: `pandas`, `NumPy`, `scikit-learn`, `Seaborn` and `Matplotlib`."]},{"cell_type":"code","metadata":{"id":"sLHoSQA03GjO"},"source":["# Dependencies\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.cluster import KMeans\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import matplotlib\n","plt.style.use('ggplot')\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pLqMU4Af3GjS"},"source":["You have imported all the dependencies that you will need in this tutorial. Now, you will load the dataset."]},{"cell_type":"code","metadata":{"id":"0wG-l_zd3GjS"},"source":["# Load the train and test datasets to create two DataFrames\n","\n","train_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv\"\n","train = pd.read_csv(train_url)\n","test_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv\"\n","test = pd.read_csv(test_url)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XbE6HRhk3GjW"},"source":["Let's preview the kind of data you will be working with by printing some samples from both the train and test DataFrames."]},{"cell_type":"code","metadata":{"id":"UPFT4_NA3GjX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678331410076,"user_tz":300,"elapsed":453,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"cd2566dc-afc1-41af-b683-90763a57f7c1"},"source":["print(\"***** Train_Set *****\")\n","print(train.head())\n","print(\"\\n\")\n","print(\"***** Test_Set *****\")\n","print(test.head())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["***** Train_Set *****\n","   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","3      0            113803  53.1000  C123        S  \n","4      0            373450   8.0500   NaN        S  \n","\n","\n","***** Test_Set *****\n","   PassengerId  Pclass                                          Name     Sex  \\\n","0          892       3                              Kelly, Mr. James    male   \n","1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n","2          894       2                     Myles, Mr. Thomas Francis    male   \n","3          895       3                              Wirz, Mr. Albert    male   \n","4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n","\n","    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n","0  34.5      0      0   330911   7.8292   NaN        Q  \n","1  47.0      1      0   363272   7.0000   NaN        S  \n","2  62.0      0      0   240276   9.6875   NaN        Q  \n","3  27.0      0      0   315154   8.6625   NaN        S  \n","4  22.0      1      1  3101298  12.2875   NaN        S  \n"]}]},{"cell_type":"markdown","metadata":{"id":"6x2uB8X63Gjc"},"source":["You can get some initial statistics of both the train and test DataFrames using pandas' `describe()` method."]},{"cell_type":"code","metadata":{"id":"d2IFhdA53Gjd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678331443745,"user_tz":300,"elapsed":196,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"6b7f4de3-851e-4bc3-aff4-820983fb8305"},"source":["print(\"***** Train_Set *****\")\n","print(train.describe())\n","print(\"\\n\")\n","print(\"***** Test_Set *****\")\n","print(test.describe())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["***** Train_Set *****\n","       PassengerId    Survived      Pclass         Age       SibSp  \\\n","count   891.000000  891.000000  891.000000  714.000000  891.000000   \n","mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n","std     257.353842    0.486592    0.836071   14.526497    1.102743   \n","min       1.000000    0.000000    1.000000    0.420000    0.000000   \n","25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n","50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n","75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n","max     891.000000    1.000000    3.000000   80.000000    8.000000   \n","\n","            Parch        Fare  \n","count  891.000000  891.000000  \n","mean     0.381594   32.204208  \n","std      0.806057   49.693429  \n","min      0.000000    0.000000  \n","25%      0.000000    7.910400  \n","50%      0.000000   14.454200  \n","75%      0.000000   31.000000  \n","max      6.000000  512.329200  \n","\n","\n","***** Test_Set *****\n","       PassengerId      Pclass         Age       SibSp       Parch        Fare\n","count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n","mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n","std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n","min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n","25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n","50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n","75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n","max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200\n"]}]},{"cell_type":"markdown","metadata":{"id":"op_HddCv3Gjg"},"source":["So, from the above outputs you definitely got to know about the features of the dataset and some basic statistics of it. I will list the feature names for you:"]},{"cell_type":"code","metadata":{"id":"TJ6zYk_s3Gjg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678331472130,"user_tz":300,"elapsed":202,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"3aac9bbb-1798-47f6-95d2-2b575c26376d"},"source":["print(train.columns.values)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n"," 'Ticket' 'Fare' 'Cabin' 'Embarked']\n"]}]},{"cell_type":"markdown","metadata":{"id":"xzVVXY833Gjj"},"source":["It is very important to note that not all machine learning algorithms support missing values in the data that you are feeding to them. K-Means being one of them. So we need to handle the missing values present in the data. Let's first see where are the values missing:"]},{"cell_type":"code","metadata":{"id":"vvKgdLHE3Gjk","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1678331541501,"user_tz":300,"elapsed":192,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"a59e355d-68d5-4f30-d635-be9f83dffdc5"},"source":["# For the train set\n","train.isna().head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   PassengerId  Survived  Pclass   Name    Sex    Age  SibSp  Parch  Ticket  \\\n","0        False     False   False  False  False  False  False  False   False   \n","1        False     False   False  False  False  False  False  False   False   \n","2        False     False   False  False  False  False  False  False   False   \n","3        False     False   False  False  False  False  False  False   False   \n","4        False     False   False  False  False  False  False  False   False   \n","\n","    Fare  Cabin  Embarked  \n","0  False   True     False  \n","1  False  False     False  \n","2  False   True     False  \n","3  False  False     False  \n","4  False   True     False  "],"text/html":["\n","  <div id=\"df-6aa0b0c6-c596-414d-b94a-009407d37fc4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6aa0b0c6-c596-414d-b94a-009407d37fc4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6aa0b0c6-c596-414d-b94a-009407d37fc4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6aa0b0c6-c596-414d-b94a-009407d37fc4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"g_DWcwV63Gjo","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1678331561899,"user_tz":300,"elapsed":218,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"9e67a781-0595-410a-d294-6716c5182ca0"},"source":["# For the test set\n","test.isna().head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   PassengerId  Pclass   Name    Sex    Age  SibSp  Parch  Ticket   Fare  \\\n","0        False   False  False  False  False  False  False   False  False   \n","1        False   False  False  False  False  False  False   False  False   \n","2        False   False  False  False  False  False  False   False  False   \n","3        False   False  False  False  False  False  False   False  False   \n","4        False   False  False  False  False  False  False   False  False   \n","\n","   Cabin  Embarked  \n","0   True     False  \n","1   True     False  \n","2   True     False  \n","3   True     False  \n","4   True     False  "],"text/html":["\n","  <div id=\"df-3a91e4d6-208c-4421-8c46-d996f5586d4c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a91e4d6-208c-4421-8c46-d996f5586d4c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3a91e4d6-208c-4421-8c46-d996f5586d4c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3a91e4d6-208c-4421-8c46-d996f5586d4c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"twoeSEpa3Gjr"},"source":["Let's get the total number of missing values in both datasets."]},{"cell_type":"code","metadata":{"id":"PNRXjMdF3Gjr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678331583384,"user_tz":300,"elapsed":237,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"9e33d23f-0485-475d-d7ba-e6b9ebd590e9"},"source":["print(\"*****In the train set*****\")\n","print(train.isna().sum())\n","print(\"\\n\")\n","print(\"*****In the test set*****\")\n","print(test.isna().sum())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["*****In the train set*****\n","PassengerId      0\n","Survived         0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age            177\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             0\n","Cabin          687\n","Embarked         2\n","dtype: int64\n","\n","\n","*****In the test set*****\n","PassengerId      0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age             86\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             1\n","Cabin          327\n","Embarked         0\n","dtype: int64\n"]}]},{"cell_type":"markdown","metadata":{"id":"jxHS1Lt33Gju"},"source":["So, you can see in the training set, in the columns Age, Cabin and Embarked, there are missing values and in the test set, the Age and Cabin columns contain missing values.\n","\n","There are a couple of ways to handle missing values:\n","\n","- Remove rows with missing values\n","- Impute missing values\n","\n","I prefer the latter one because if you remove the rows with missing values it can cause insufficiency in the data which in turn results in inefficient training of the machine learning model.\n","\n","Now, there are several ways you can perform the imputation:\n","\n","- A constant value that has meaning within the domain, such as 0, distinct from all other values.\n","- A value from another randomly selected record.\n","- A mean, median or mode value for the column.\n","- A value estimated by another machine learning model.\n","\n","Any imputation performed on the train set will have to be performed on test data in the future when predictions are needed from the final machine learning model. This needs to be taken into consideration when choosing how to impute the missing values.\n","\n","Pandas provides the `fillna()` function for replacing missing values with a specific value. Let's apply that with Mean Imputation."]},{"cell_type":"code","metadata":{"id":"wTgPtLCw3Gjv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678331735527,"user_tz":300,"elapsed":359,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"8ecb4ff5-a8a4-4cd6-e14b-8568020d7963"},"source":["# Fill missing values with mean column values in the train set\n","train.fillna(train.mean(), inplace=True)\n","\n","# Fill missing values with mean column values in the test set\n","test.fillna(test.mean(), inplace=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-9-33c3067c13b2>:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n","  train.fillna(train.mean(), inplace=True)\n","<ipython-input-9-33c3067c13b2>:5: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n","  test.fillna(test.mean(), inplace=True)\n"]}]},{"cell_type":"markdown","metadata":{"id":"LNl1ju_N3Gjx"},"source":["Now that you have imputed the missing values in the dataset, it's time to see if the dataset still has any missing values.\n","\n","For the training dataset:"]},{"cell_type":"code","metadata":{"id":"lzu_Do2H3Gjy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678331762489,"user_tz":300,"elapsed":199,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"7b332395-99f0-4584-da49-69f72f22fee9"},"source":["print(train.isna().sum())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PassengerId      0\n","Survived         0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age              0\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             0\n","Cabin          687\n","Embarked         2\n","dtype: int64\n"]}]},{"cell_type":"markdown","metadata":{"id":"yL5QzgRy3Gj1"},"source":["Let's see if you have any missing values in the test set."]},{"cell_type":"code","metadata":{"id":"9u6gGoLb3Gj1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678331782740,"user_tz":300,"elapsed":241,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"c6d68e5d-e13e-4415-fafe-14d83a5d26f8"},"source":["print(test.isna().sum())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PassengerId      0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age              0\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             0\n","Cabin          327\n","Embarked         0\n","dtype: int64\n"]}]},{"cell_type":"markdown","metadata":{"id":"-uPJOo0V3Gj5"},"source":["Yes, you can see there are still some missing values in the Cabin and Embarked columns. This is because these values are non-numeric. In order to perform the imputation the values need to be in numeric form. There are ways to convert a non-numeric value to a numeric one. More on this later.\n","\n","Let's do some more analytics in order to understand the data better. Understanding is really required in order to perform any Machine Learning task. Let's start with finding out which features are categorical and which are numerical.\n","\n","- Categorical: Survived, Sex, and Embarked. Ordinal: Pclass.\n","- Continuous: Age, Fare. Discrete: SibSp, Parch.\n","\n","Two features are left out which are not listed above in any of the categories. Yes, you guessed it right, Ticket and Cabin. Ticket is a mix of numeric and alphanumeric data types. Cabin is alphanumeric. Let see some sample values."]},{"cell_type":"code","metadata":{"id":"5SEVGGaD3Gj6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678331816633,"user_tz":300,"elapsed":188,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"13c06e35-b179-4f67-fb87-5a42dbc16d6b"},"source":["train['Ticket'].head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0           A/5 21171\n","1            PC 17599\n","2    STON/O2. 3101282\n","3              113803\n","4              373450\n","Name: Ticket, dtype: object"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"VwJ1GD3O3Gj9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678331843719,"user_tz":300,"elapsed":231,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"22fb4b3f-578e-4fd6-838f-a23c36db1455"},"source":["train['Cabin'].head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0     NaN\n","1     C85\n","2     NaN\n","3    C123\n","4     NaN\n","Name: Cabin, dtype: object"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"3oFzabQT3GkA"},"source":["Let's see the survival count of passengers with respect to the following features:\n","\n","- Pclass\n","- Sex\n","- SibSp\n","- Parch\n","- Let's do that one by one:\n","\n","Survival count with respect to Pclass:"]},{"cell_type":"code","metadata":{"id":"xQbq28qp3GkB","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1678331948207,"user_tz":300,"elapsed":233,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"3b186633-66fa-4655-a523-587e59b45fe2"},"source":["train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Pclass  Survived\n","0       1  0.629630\n","1       2  0.472826\n","2       3  0.242363"],"text/html":["\n","  <div id=\"df-12dbc5c9-4d98-4ab6-a373-7b632ded88c4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pclass</th>\n","      <th>Survived</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.629630</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0.472826</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0.242363</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12dbc5c9-4d98-4ab6-a373-7b632ded88c4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-12dbc5c9-4d98-4ab6-a373-7b632ded88c4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-12dbc5c9-4d98-4ab6-a373-7b632ded88c4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"yImRx3eS3GkD"},"source":["Survival count with respect to Sex:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"UkzCd9D_3GkE","colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"status":"ok","timestamp":1678331993704,"user_tz":300,"elapsed":233,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"c9fafc45-8ad3-40f9-f8e1-436a13d89358"},"source":["train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Sex  Survived\n","0  female  0.742038\n","1    male  0.188908"],"text/html":["\n","  <div id=\"df-650a6461-9390-4ee7-80b3-6d029ffb0237\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sex</th>\n","      <th>Survived</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>female</td>\n","      <td>0.742038</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>male</td>\n","      <td>0.188908</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-650a6461-9390-4ee7-80b3-6d029ffb0237')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-650a6461-9390-4ee7-80b3-6d029ffb0237 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-650a6461-9390-4ee7-80b3-6d029ffb0237');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"HAwZxcih3GkH"},"source":["You can see the survival rate of female passengers is significantly higher for males.\n","\n","Survival count with respect to SibSp:"]},{"cell_type":"code","metadata":{"id":"baGQCeL-3GkI","colab":{"base_uri":"https://localhost:8080/","height":269},"executionInfo":{"status":"ok","timestamp":1678332013925,"user_tz":300,"elapsed":185,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"6948461d-03d3-4db6-b86c-76448e28e007"},"source":["train[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   SibSp  Survived\n","1      1  0.535885\n","2      2  0.464286\n","0      0  0.345395\n","3      3  0.250000\n","4      4  0.166667\n","5      5  0.000000\n","6      8  0.000000"],"text/html":["\n","  <div id=\"df-c7aed3e5-4e5e-4dda-a73d-3bd077a91705\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SibSp</th>\n","      <th>Survived</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.535885</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.464286</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.345395</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0.250000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0.166667</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>8</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7aed3e5-4e5e-4dda-a73d-3bd077a91705')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c7aed3e5-4e5e-4dda-a73d-3bd077a91705 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c7aed3e5-4e5e-4dda-a73d-3bd077a91705');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"1EUr-_Y93GkM"},"source":["Now it's time for some quick plotting. Let's first plot the graph of \"Age vs. Survived\":"]},{"cell_type":"code","metadata":{"id":"3ACdcl3e3GkM","colab":{"base_uri":"https://localhost:8080/","height":243},"executionInfo":{"status":"ok","timestamp":1678332067903,"user_tz":300,"elapsed":1083,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"38e2ab35-daf2-45d5-d6e7-3b34497b2158"},"source":["g = sns.FacetGrid(train, col='Survived')\n","g.map(plt.hist, 'Age', bins=20)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<seaborn.axisgrid.FacetGrid at 0x7f4434c478e0>"]},"metadata":{},"execution_count":17},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x216 with 2 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAagAAADQCAYAAABStPXYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAASmUlEQVR4nO3de7BdZXnH8e9LUlAQxXg05iRAcIoySAe0KI5FS71rEbDWtxCFqEi01dFatKPOMGiVGZx6o96DF0C5PSpKREahtEqrRQUtVsBaVC6BkJAGEMEBE9/+sdaB3XBuOWfvs9+99/czcyZ7Xc7az1k5z/nt9e6110qlFCRJqs1O/S5AkqTJGFCSpCoZUJKkKhlQkqQqGVCSpCoZUJKkKhlQQySl9KmU0kk92O67U0pf7PZ2pYVibwwmA6rHUkqHppS+l1K6K6W0JaX03ZTS03rxXKWUN5RS3tuLbfdCSmlVSunGlNI9KaWvpZSW9LsmLRx7Y3IppWUppXUppVtTSiWltLLfNfWLAdVDKaVHAhcBHwWWAMuB9wD3zWFbKaU0NP9fKaUnA58GjgWWAvcCn+hrUVow9sa0fg98E3h5vwvpt2H6T63REwFKKeeWUraVUn5bSrmklPITeOjwQEppZfuKaXE7/e2U0ikppe/S/AF/e0rpys4nSCm9NaW0rn18Rkrpfe3j61JKh3estzildHtK6ant9DPaV693ppSuTikd1rHuPiml76SU7k4pXQqM9WDfvBL4einl8lLKb4CTgL9IKe3eg+dSfeyNKZRSNpZSPgH8sNvbHjQGVG/9HNiWUjozpfTilNKj57CNY4E1wO7Ap4AnpZT27Vi+Cjhnku87FzimY/qFwOZSyo9SSsuBbwDvo3n1+jbgKymlx7brngNcRdN87wVWT1VcSmmvtpGn+lo1xbc+Gbh6YqKU8gvgfto/XBp69sbUvaGWAdVDpZRfA4cCBTgduL0dW166A5s5o5RyTSllaynlLuBC2uZqm3E/YN0k33cOcERKadd2ehVNYwK8Cri4lHJxKeX3pZRLgSuBl6SU9gKeBpxUSrmvlHI58PVpfsabSil7TPM12R8IgEcAd2037y6aPzYacvbGtL2hlgHVY6WU60opry6lrAAOAMaBj+zAJm7ebvocHnz1twr4Winl3kme93rgOuClbSMewYOvJvcGXtH5ao7mj8Wytr47Sin3dGzuxh2od7Z+Azxyu3mPBO7uwXOpQvaGZrK43wWMklLKz1JKZwCvb2fdA+zascrjJ/u27aYvBR6bUjqIphnfOs1TTgxl7ARc2zYmNI39hVLKCdt/Q0ppb+DRKaXdOhpxr0nqmFh/L+DaaWp4fSnl7EnmXwMc2LGdJwC70Az9aMTYG5qMR1A9lFLaL6V0YkppRTu9J01TXNGu8p/As9ux6kcB75xpm6WU3wFfAv6RZoz80mlWPw94AfDX/P+x+C/SvHp8YUppUUrpYSmlw1JKK0opN9IMabwnpbRzSulQ4KXT1HNTKeUR03xN1YBntzU8K6W0G/APwAWlFI+gRoC9MW1vkFJ6GM0LNoBd2umRY0D11t3AIcD3U0r30DTfT4ETAdrx7fOBn9C88XrRLLd7DvA84EullK1TrVRK2QD8B/DM9nkm5t8MHAm8C7id5lXj23nw92FVW/cW4GTgrFnWNWullGuAN9AE1Saa957+ptvPo2rZG9P7Lc0wOMDP2umRk7xhoSSpRh5BSZKqZEBJkqpkQEmSqmRASZKqVMvnoMqtt9465cIlS5awZcuWBSxnbqyz+wal1pnqHB8fT3PctL2xwAal1mGpc7reGIgjqJ12GogyrbMHBqXWftXp/um+Qal1FOocjJ9QkjRyDChJUpUMKElSlQwoSVKVDChJUpVqOc18pG074Yhply86fbJ7rknScPMISpJUJQNKklQlA0qSVCUDSpJUJQNKklQlA0qSVCUDSpJUJQNKklQlA0qSVCUDSpJUJQNKklQlA0qSVCUDSpJUJQNKklQlA0qSVCUDSpJUJQNKklQlA0qSVKUZb/mec/4ccDiwKSIOaOe9GzgBuL1d7V0RcXG77J3A8cA24M0R8a0e1C1JGnIzBhRwBvAx4Kzt5n84Ij7QOSPnvD9wNPBkYBz455zzEyNiWxdqlSSNkBmH+CLicmDLLLd3JHBeRNwXEb8CrgeePo/6JEkjajZHUFN5U875OOBK4MSIuANYDlzRsc76dp4kSTtkrgH1SeC9QGn//SDw2h3ZQM55DbAGICIYGxubusjFi6ddXou51rlxhuXd/tkHZX/C4NTazTrtjf4alFpHoc45BVREPPA3Ned8OnBRO3kLsGfHqivaeZNtYy2wtp0smzdvnvL5xsbGmG55LXpVZ7e3OSj7Ewan1pnqHB8fn/W27I3+GpRah6XO6XpjTqeZ55yXdUy+DPhp+3gdcHTOeZec8z7AvsAP5vIckqTRNpvTzM8FDgPGcs7rgZOBw3LOB9EM8d0AvB4gIq7JOQdwLbAVeKNn8EmS5mLGgIqIYyaZ/dlp1j8FOGU+RUmS5JUkJElVMqAkSVUyoCRJVTKgJElVMqAkSVUyoCRJVTKgJElVMqAkSVUyoCRJVTKgJElVMqAkSVUyoCRJVTKgJElVMqAkSVUyoCRJVTKgJElVMqAkSVUyoCRJVTKgJElVMqAkSVUyoCRJVTKgJElVMqAkSVUyoCRJVTKgJElVMqAkSVUyoCRJVTKgJElVMqAkSVUyoCRJVVo80wo5588BhwObIuKAdt4S4HxgJXADkCPijpxzAk4DXgLcC7w6In7Um9IlScNsNkdQZwAv2m7eO4DLImJf4LJ2GuDFwL7t1xrgk90pU5I0amYMqIi4HNiy3ewjgTPbx2cCR3XMPysiSkRcAeyRc17WpVolSSNkxiG+KSyNiA3t49uApe3j5cDNHeutb+dtYDs55zU0R1lEBGNjY1MXuXjxtMtrMdc6N86wvNs/+6DsTxicWrtZp73RX4NS6yjUOdeAekBElJxzmcP3rQXWtpNl8+bNU647NjbGdMtr0as6u73NQdmfMDi1zlTn+Pj4rLdlb/TXoNQ6LHVO1xtzPYtv48TQXfvvpnb+LcCeHeutaOdJkrRD5noEtQ5YDZza/nthx/w35ZzPAw4B7uoYCpQkadZmc5r5ucBhwFjOeT1wMk0wRc75eOBGILerX0xzivn1NKeZv6YHNUuSRsCMARURx0yx6LmTrFuAN863KEmSvJKEJKlKBpQkqUoGlCSpSgaUJKlK8/6griQtlG0nHDHt8kWnr1ugSrQQPIKSJFXJgJIkVcmAkiRVyYCSJFXJgJIkVcmAkiRVyYCSJFXJgJIkVcmAkiRVyYCSJFXJgJIkVcmAkiRVyYCSJFXJgJIkVcmAkiRVyYCSJFXJgJIkVcmAkiRVyYCSJFXJgJIkVcmAkiRVyYCSJFXJgJIkVWlxvwsYBdtOOKLfJUjSwJlXQOWcbwDuBrYBWyPi4JzzEuB8YCVwA5Aj4o75lSlJGjXdGOL7s4g4KCIObqffAVwWEfsCl7XTkiTtkF68B3UkcGb7+EzgqB48hyRpyM33PagCXJJzLsCnI2ItsDQiNrTLbwOWTvaNOec1wBqAiGBsbGzqIhcvnnb5Qtj4smdOuWzpV78HTF3nxnk+d7d/9hr252wNSq3drHPQemM2ulXnTL3UjecYtX3aa/Opc74BdWhE3JJzfhxwac75Z50LI6K04fUQbZitbSfL5s2bp3ySsbExplvebxO19arObm+z9v3ZaVBqnanO8fHxWW9rmHpjwkLV2Y3ncJ9213x6Y14BFRG3tP9uyjl/FXg6sDHnvCwiNuSclwGb5vMcg2DiLL35HilJkh405/egcs675Zx3n3gMvAD4KbAOWN2uthq4cL5FSpJGz3xOklgK/HvO+WrgB8A3IuKbwKnA83PO/wM8r52WJGmHzHmILyJ+CRw4yfz/BZ47n6IkSfJSR5KkKhlQkqQqGVCSpCoZUJKkKhlQkqQqebsNSQtiptvOLDp93QJVokFhQEkaGrO595pBODgMqAHnq1JJw8r3oCRJVTKgJElVcohvAMxmXF0adP6ea3sG1JCbrOk7bwvie1SSamVASQOulhNlpqvDe6VpLnwPSpJUJQNKklQlh/g0pVqGjiSNJo+gJElVMqAkSVUyoCRJVTKgJElV8iSJEeen9zVqZvyd/+r3FqYQzciA0px5lt/o8IWM+sGAkqQu88VbdwxUQPmfLkmjY6ACaj4MN0mzsfFlz+x3CWp5Fp8kqUojcwQljarZnODgCIJqZECpZ7px5tdUt2nwD6oGmS8aZseA0kDyPUVp+A1VQM3nFbuf85BUEz9Q3MOAyjm/CDgNWAR8JiJO7dVzSTvCo6+H8gXa4JnpbMNh+D3uSUDlnBcBHweeD6wHfphzXhcR1/bi+aTt+QdXGny9OoJ6OnB9RPwSIOd8HnAkYEBJ0hDp5VBkrwJqOXBzx/R64JDOFXLOa4A1ABHB+Pj4tBscHx+Hb1zZ5TKl7pnhd7gAaTbb2dHe2NO+UD/N4vdvrr3Rtw/qRsTaiDg4Ig6mKW7Kr5zzVTOtU8OXdY5urbOsc1bsDWsdwTon1auAugXYs2N6RTtPkqRZ6dUQ3w+BfXPO+9AE09HAqh49lyRpCPXkCCoitgJvAr4FXNfMimvmscm1XSms96yz+wal1n7V6f7pvkGpdejrTKWUbhYiSVJXeDVzSVKVDChJUpWqvhZfrZdLyjnvCZwFLKU5h39tRJyWc14CnA+sBG4AckTc0a86J7RX9rgSuCUiDm9PXjkPeAxwFXBsRNzfzxoBcs57AJ8BDqDZr68F/pvK9mnO+a3A62hq/C/gNcAyFnif2h/dMQj9Maq9Ue0RVMflkl4M7A8ck3Pev79VPWArcGJE7A88A3hjW9s7gMsiYl/gsna6Bm+hOVllwvuBD0fEHwJ3AMf3paqHOg34ZkTsBxxIU3NV+zTnvBx4M3BwRBxAEw5Hs8D71P7oqkHoj5HsjWoDio7LJbVpO3G5pL6LiA0R8aP28d00vyzLaeo7s13tTOCovhTYIee8Avhzmldf5JwT8Bzgy+0qtdT5KODZwGcBIuL+iLiTCvcpzcjDw3POi4FdgQ0s/D61P7pgEPpjlHuj5iG+GS+XVIOc80rgKcD3gaURsaFddBvNEEe/fQT4e2D3dvoxwJ3tRwGg2a/L+1DX9vYBbgc+n3M+kGYo4C1Utk8j4pac8weAm4DfApfQ1LrQ+9T+6I6PUH9/jGxv1HwEVb2c8yOArwB/GxG/7lwWEYVmHLZvcs6HA5si4qp+1jFLi4GnAp+MiKcA97DdkEUl+/TRNK9c9wHGgd2AF/WzplrZH10zsr1Rc0BVfbmknPMf0DTf2RFxQTt7Y855Wbt8GbCpX/W1/gQ4Iud8A80Q0HNoxrL3aA/BoZ79uh5YHxHfb6e/TNOUte3T5wG/iojbI+J3wAU0+3mh96n9MX+D0h8j2xs1B9QDl0vKOe9M82ZbFXfgasepPwtcFxEf6li0DljdPl4NXLjQtXWKiHdGxIqIWEmz//4lIl4J/Cvwl+1qfa8TICJuA27OOT+pnfVcmtuzVLVPaYYvnpFz3rX9PZioc6H3qf0xT4PSH6PcG1VfSSLn/BKaMeJFwOci4pT+VtTIOR8K/BvNaZS/b2e/i2acPYC9gBtpTvvc0pcit5NzPgx4W3sa7RNoXjEuAX4MvCoi7utnfQA554No3qzeGfglzSmqO1HZPs05vwf4K5qz1X5Mc1rtchZ4n9of3VN7f4xqb1QdUJKk0VXzEJ8kaYQZUJKkKhlQkqQqGVCSpCoZUJKkKhlQkqQq1XwtPs1RzvnbNFc8fny/P78h1cTeGCweQQ2Z9uKcz6K5LtcR/a1Gqoe9MXg8gho+xwFX0HxqfzXwJYCc82OAM4A/pbnR2beAwyLi0Hb5fsBHgT+muXLySRERC1281EP2xoDxCGr4HAec3X69MOc8cQn+j9NcBfnxNM05cQ0vcs67AZcC5wCPo7ku2ScqugGe1A32xoAxoIZIew20vYFobyHwC2BVe/fVlwMnR8S9EXEtD97oDOBw4IaI+HxEbI2IH9NcifoVC/wjSD1hbwwmh/iGy2rgkojY3E6f0847l+b/uvMGd52P9wYOyTnf2TFvMfCF3pUqLSh7YwAZUEMi5/xwIAOLcs63tbN3AfagudPmVpp7sfy8XdZ5L6Gbge9ExPMXplpp4dgbg8uAGh5HAduAPwLu75gfNGPvFwDvzjm/juby/MfR3L8F4CLg1JzzsTSXxQc4CPhNRFzX88ql3joKe2MgGVDDYzXw+Yi4qXNmzvljwD/RNOcZwG00ZyqdCxwMEBF355xfAHyo/doJuBr4u4UqXuohe2NAeT+oEZVzfj/NhxVXz7iyNELsjXp4BDUi2s9y7Exzl9OnAcfT3O1SGmn2Rr0MqNGxO83QxTiwEfggcGFfK5LqYG9UyiE+SVKV/KCuJKlKBpQkqUoGlCSpSgaUJKlKBpQkqUr/BxnxcEvfIHpxAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"yeyNasXy3GkP"},"source":["Its time to see how the Pclass and Survived features are related to eachother with a graph:"]},{"cell_type":"code","metadata":{"id":"5RYtg5xf3GkP","colab":{"base_uri":"https://localhost:8080/","height":522},"executionInfo":{"status":"ok","timestamp":1678332124876,"user_tz":300,"elapsed":1851,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"9f8d449b-895f-4580-9291-7b36a84fc8df"},"source":["grid = sns.FacetGrid(train, col='Survived', row='Pclass', size=2.2, aspect=1.6)\n","grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n","grid.add_legend();"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/seaborn/axisgrid.py:337: UserWarning: The `size` parameter has been renamed to `height`; please update your code.\n","  warnings.warn(msg, UserWarning)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 514.88x475.2 with 6 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"czf78C533GkR"},"source":["Enough of visualization and analytics for now! Let's actually build a K-Means model with the training set. But before that you will need some data preprocessing as well. You can see that not all the feature values are of same type. Some of them are numerical and some of them are not. In order to ease the computation, you will feed all numerical data to the model. Let's see the data types of different features that you have:"]},{"cell_type":"code","metadata":{"id":"QNIrpH7j3GkS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678332233893,"user_tz":300,"elapsed":193,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"5c81e6ce-f8bf-43ef-8771-c256069cf1b6"},"source":["train.info()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 891 entries, 0 to 890\n","Data columns (total 12 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   PassengerId  891 non-null    int64  \n"," 1   Survived     891 non-null    int64  \n"," 2   Pclass       891 non-null    int64  \n"," 3   Name         891 non-null    object \n"," 4   Sex          891 non-null    object \n"," 5   Age          891 non-null    float64\n"," 6   SibSp        891 non-null    int64  \n"," 7   Parch        891 non-null    int64  \n"," 8   Ticket       891 non-null    object \n"," 9   Fare         891 non-null    float64\n"," 10  Cabin        204 non-null    object \n"," 11  Embarked     889 non-null    object \n","dtypes: float64(2), int64(5), object(5)\n","memory usage: 83.7+ KB\n"]}]},{"cell_type":"markdown","metadata":{"id":"gCMkvReF3GkV"},"source":["So, you can see that the following features are non-numeric:\n","\n","- Name\n","- Sex\n","- Ticket\n","- Cabin\n","- Embarked\n","\n","Before converting them into numeric ones, you might want to do some feature engineering, i.e. features like Name, Ticket, Cabin and Embarked do not have any impact on the survival status of the passengers. Often, it is better to train your model with only significant features than to train it with all the features, including unnecessary ones. It not only helps in efficient modelling, but also the training of the model can happen in much lesser time. Although, feature engineering is a whole field of study itself, I will encourage you to dig it further. But for this tutorial, know that the features Name, Ticket, Cabin and Embarked can be dropped and they will not have significant impact on the training of the K-Means model."]},{"cell_type":"code","metadata":{"id":"XanBS6tE3GkV"},"source":["train = train.drop(['Name','Ticket', 'Cabin','Embarked'], axis=1)\n","test = test.drop(['Name','Ticket', 'Cabin','Embarked'], axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CiMJV3kM3GkX"},"source":["Now that the dropping part is done let's convert the 'Sex' feature to a numerical one (only 'Sex' is remaining now which is a non-numeric feature). You will do this using a technique called [Label Encoding](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."]},{"cell_type":"code","metadata":{"id":"jigCCDkb3GkZ"},"source":["labelEncoder = LabelEncoder()\n","labelEncoder.fit(train['Sex'])\n","labelEncoder.fit(test['Sex'])\n","train['Sex'] = labelEncoder.transform(train['Sex'])\n","test['Sex'] = labelEncoder.transform(test['Sex'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bu0-GNeM3Gkd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678332428641,"user_tz":300,"elapsed":188,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"a826fdd6-b5a5-4001-be6b-9a0bb6db001f"},"source":["# Let's investigate if you have non-numeric data left\n","\n","train.info()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 891 entries, 0 to 890\n","Data columns (total 8 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   PassengerId  891 non-null    int64  \n"," 1   Survived     891 non-null    int64  \n"," 2   Pclass       891 non-null    int64  \n"," 3   Sex          891 non-null    int64  \n"," 4   Age          891 non-null    float64\n"," 5   SibSp        891 non-null    int64  \n"," 6   Parch        891 non-null    int64  \n"," 7   Fare         891 non-null    float64\n","dtypes: float64(2), int64(6)\n","memory usage: 55.8 KB\n"]}]},{"cell_type":"markdown","metadata":{"id":"NWZ_OnXU3Gkg"},"source":["Note that the test set does not have the Survived feature."]},{"cell_type":"code","metadata":{"id":"xEcVPVns3Gkh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678332462470,"user_tz":300,"elapsed":209,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"92050214-7c5b-42c5-f7d0-db3776c812b4"},"source":["test.info()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 418 entries, 0 to 417\n","Data columns (total 7 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   PassengerId  418 non-null    int64  \n"," 1   Pclass       418 non-null    int64  \n"," 2   Sex          418 non-null    int64  \n"," 3   Age          418 non-null    float64\n"," 4   SibSp        418 non-null    int64  \n"," 5   Parch        418 non-null    int64  \n"," 6   Fare         418 non-null    float64\n","dtypes: float64(2), int64(5)\n","memory usage: 23.0 KB\n"]}]},{"cell_type":"markdown","metadata":{"id":"YqFT7INg3Gkj"},"source":["**Brilliant!**\n","\n","Looks like you are good to go to train your K-Means model now.\n","\n","You can first drop the Survival column from the data with the `drop()` function."]},{"cell_type":"code","metadata":{"id":"mbzrfZ5w3Gkk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678332512971,"user_tz":300,"elapsed":292,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"f51ab265-d89a-4459-f0c5-ce7d905032cb"},"source":["X = np.array(train.drop(['Survived'], 1).astype(float))\n","\n","y = np.array(train['Survived'])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-24-f45639e93356>:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n","  X = np.array(train.drop(['Survived'], 1).astype(float))\n"]}]},{"cell_type":"markdown","metadata":{"id":"M8jJ7wOV3Gkm"},"source":["You can review all the features you are going to feed to the algorithm with `train.info()`."]},{"cell_type":"code","metadata":{"id":"WA96opzq3Gkn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678332580505,"user_tz":300,"elapsed":213,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"b7a76705-c5fc-4495-a637-c1bb6ddf450b"},"source":["train.info()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 891 entries, 0 to 890\n","Data columns (total 8 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   PassengerId  891 non-null    int64  \n"," 1   Survived     891 non-null    int64  \n"," 2   Pclass       891 non-null    int64  \n"," 3   Sex          891 non-null    int64  \n"," 4   Age          891 non-null    float64\n"," 5   SibSp        891 non-null    int64  \n"," 6   Parch        891 non-null    int64  \n"," 7   Fare         891 non-null    float64\n","dtypes: float64(2), int64(6)\n","memory usage: 55.8 KB\n"]}]},{"cell_type":"markdown","metadata":{"id":"Y5j_FGEI3Gkq"},"source":["Let's now build the K-Means model."]},{"cell_type":"code","metadata":{"id":"8F3oH1WV3Gkq","colab":{"base_uri":"https://localhost:8080/","height":132},"executionInfo":{"status":"ok","timestamp":1678332614530,"user_tz":300,"elapsed":681,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"cd3652e3-4646-4a96-a154-41c7a1211674"},"source":["kmeans = KMeans(n_clusters=2) # You want cluster the passenger records into 2: Survived or Not survived\n","kmeans.fit(X)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["KMeans(n_clusters=2)"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=2)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"bxUVb-hT3Gku"},"source":["You can see all the other parameters of the model other than `n_clusters`. Let's see how well the model is doing by looking at the percentage of passenger records that were clustered correctly."]},{"cell_type":"code","metadata":{"id":"EXJLVFop3Gku","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678332649312,"user_tz":300,"elapsed":732,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"3734dbb7-9950-4e45-fa54-1ae4c706c139"},"source":["correct = 0\n","for i in range(len(X)):\n","    predict_me = np.array(X[i].astype(float))\n","    predict_me = predict_me.reshape(-1, len(predict_me))\n","    prediction = kmeans.predict(predict_me)\n","    if prediction[0] == y[i]:\n","        correct += 1\n","\n","print(correct/len(X))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.5084175084175084\n"]}]},{"cell_type":"markdown","metadata":{"id":"26nMhq0a3Gkw"},"source":["That is nice for the first go. Your model was able to cluster correctly with a 50% (accuracy of your model). But in order to enhance the performance of the model you could tweak some parameters of the model itself. I will list some of these parameters which the scikit-learn implementation of K-Means provides:\n","\n","- algorithm\n","- max_iter\n","- n_jobs \n","\n","Let's tweak the values of these parameters and see if there is a change in the result.\n","\n","In the [scikit-learn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html), you will find a solid information about these parameters which you should dig further."]},{"cell_type":"code","metadata":{"id":"YcgIiY4L3Gkx","colab":{"base_uri":"https://localhost:8080/","height":169},"executionInfo":{"status":"ok","timestamp":1678332769710,"user_tz":300,"elapsed":210,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"9078ddbe-635e-4c5b-f345-d2846bdcc5e6"},"source":["kmeans = kmeans = KMeans(n_clusters=2, max_iter=600, algorithm = 'auto')\n","kmeans.fit(X)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:1366: FutureWarning: algorithm='auto' is deprecated, it will be removed in 1.3. Using 'lloyd' instead.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["KMeans(algorithm='auto', max_iter=600, n_clusters=2)"],"text/html":["<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(algorithm=&#x27;auto&#x27;, max_iter=600, n_clusters=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(algorithm=&#x27;auto&#x27;, max_iter=600, n_clusters=2)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"OidvO05l3Gkz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678332788282,"user_tz":300,"elapsed":443,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"6babf842-8294-4132-cb06-3f89bcfb58cb"},"source":["correct = 0\n","for i in range(len(X)):\n","    predict_me = np.array(X[i].astype(float))\n","    predict_me = predict_me.reshape(-1, len(predict_me))\n","    prediction = kmeans.predict(predict_me)\n","    if prediction[0] == y[i]:\n","        correct += 1\n","\n","print(correct/len(X))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.5072951739618407\n"]}]},{"cell_type":"markdown","metadata":{"id":"SnSPfIFs3Gk2"},"source":["You can see a decrease in the score. One of the reasons being you have not scaled the values of the different features that you are feeding to the model. The features in the dataset contain different ranges of values. So, what happens is a small change in a feature does not affect the other feature. So, it is also important to scale the values of the features to a same range.\n","\n","Let's do that now and for this experiment you are going to take `[0,1]` as the uniform value range across all the features."]},{"cell_type":"code","metadata":{"id":"dX4YopHc3Gk3"},"source":["scaler = MinMaxScaler()\n","X_scaled = scaler.fit_transform(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ib2jBJ-B3Gk6","colab":{"base_uri":"https://localhost:8080/","height":169},"executionInfo":{"status":"ok","timestamp":1678332870938,"user_tz":300,"elapsed":193,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"1569b76b-a091-4218-828b-cfa968d93b88"},"source":["kmeans.fit(X_scaled)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:1366: FutureWarning: algorithm='auto' is deprecated, it will be removed in 1.3. Using 'lloyd' instead.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["KMeans(algorithm='auto', max_iter=600, n_clusters=2)"],"text/html":["<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(algorithm=&#x27;auto&#x27;, max_iter=600, n_clusters=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(algorithm=&#x27;auto&#x27;, max_iter=600, n_clusters=2)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"-pVWsXb53Gk-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678332881316,"user_tz":300,"elapsed":181,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"524504dd-c6de-463d-cf65-abf88de23189"},"source":["correct = 0\n","for i in range(len(X)):\n","    predict_me = np.array(X[i].astype(float))\n","    predict_me = predict_me.reshape(-1, len(predict_me))\n","    prediction = kmeans.predict(predict_me)\n","    if prediction[0] == y[i]:\n","        correct += 1\n","\n","print(correct/len(X))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.6262626262626263\n"]}]},{"cell_type":"markdown","metadata":{"id":"6YXi4AqD3GlE"},"source":["Great! You can see an instant 12% increase in the score.\n","\n","So far you were able to load your data, preprocess it accordingly, do a little bit of feature engineering and finally you were able to make a K-Means model and see it in action.\n","\n","Now, let's discuss K-Means's limitations.\n","\n","\n","## Disadvantages of K-Means\n","Now that you have a fairly good idea on how K-Means algorithm works let's discuss some its disadvantages.\n","\n","The biggest disadvantage is that K-Means requires you to pre-specify the number of clusters (k). However, for the Titanic dataset, you had some domain knowledge available that told you the number of people who survived in the shipwreck. This might not always be the case with real world datasets. Hierarchical clustering is an alternative approach that does not require a particular choice of clusters. An additional disadvantage of k-means is that it is sensitive to outliers and different results can occur if you change the ordering of the data.\n","\n","K-Means is a lazy learner where generalization of the training data is delayed until a query is made to the system. This means K-Means starts working only when you trigger it to, thus lazy learning methods can construct a different approximation or result to the target function for each encountered query. It is a good method for online learning, but it requires a possibly large amount of memory to store the data, and each request involves starting the identification of a local model from scratch."]},{"cell_type":"markdown","source":["## The latest development - HDBSCAN\n","\n","HDBSCAN - Hierarchical Density-Based Spatial Clustering of Applications with Noise. Performs DBSCAN over varying epsilon values and integrates the result to find a clustering that gives the best stability over epsilon. This allows HDBSCAN to find clusters of varying densities (unlike DBSCAN), and be more robust to parameter selection.\n","\n","In practice this means that HDBSCAN returns a good clustering straight away with little or no parameter tuning -- and the primary parameter, minimum cluster size, is intuitive and easy to select.\n","\n","HDBSCAN is ideal for exploratory data analysis; it's a fast and robust algorithm that you can trust to return meaningful clusters (if there are any)."],"metadata":{"id":"KZoRDblS1G7h"}},{"cell_type":"code","source":["!pip install hdbscan"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K4RyaZ-x1GgB","executionInfo":{"status":"ok","timestamp":1678333176910,"user_tz":300,"elapsed":98574,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"5864e0c5-0cf3-449f-ea21-36b0d977eb6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hdbscan\n","  Downloading hdbscan-0.8.29.tar.gz (5.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from hdbscan) (1.22.4)\n","Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.9/dist-packages (from hdbscan) (1.2.1)\n","Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.9/dist-packages (from hdbscan) (0.29.33)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.9/dist-packages (from hdbscan) (1.10.1)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.9/dist-packages (from hdbscan) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20->hdbscan) (3.1.0)\n","Building wheels for collected packages: hdbscan\n","  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hdbscan: filename=hdbscan-0.8.29-cp39-cp39-linux_x86_64.whl size=3582062 sha256=28040322080fbd0e2c72171cce1c5136ac4df3d7e3924308ee0b1c490857b147\n","  Stored in directory: /root/.cache/pip/wheels/05/6f/88/1a4c04276b98306f00217a1e300e6ba0252c6aa4f7616067ae\n","Successfully built hdbscan\n","Installing collected packages: hdbscan\n","Successfully installed hdbscan-0.8.29\n"]}]},{"cell_type":"code","source":["import hdbscan\n","clusterer = hdbscan.HDBSCAN()\n","cluster_labels = clusterer.fit_predict(X)\n","cluster_labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hkQwhn1s2JPN","executionInfo":{"status":"ok","timestamp":1678333176911,"user_tz":300,"elapsed":16,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"1952810f-4056-4cd8-8144-6290a7667e89"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0, -1,  0, -1,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0, -1,  0, -1,\n","       -1, -1,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,\n","        0, -1,  0, -1,  0,  0,  0,  0,  0,  0, -1, -1,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0, -1,  0,  0,  0, -1,  0, -1,  0, -1,  0,  0,  0,  0,  0,\n","       -1,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0, -1,  0, -1,\n","       -1, -1,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0, -1,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,\n","        0,  0, -1,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  1,  0,  0,  1,\n","        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0, -1,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0, -1,  0,  0,\n","        0,  0,  0, -1,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0, -1,  0,  0, -1,  0,  0,  0,  0,  0,  0,\n","        0, -1, -1, -1,  0,  0, -1, -1,  0,  0,  0, -1,  0, -1, -1,  0,  0,\n","        0,  0,  0, -1,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0, -1, -1,  0,  0,  0,  0,  0, -1,  0, -1,  0,  0,  0,  0,  0, -1,\n","       -1, -1,  0, -1, -1, -1,  0,  0,  0,  0,  0,  0, -1, -1,  0,  0,  0,\n","        0, -1, -1, -1,  0,  0, -1,  0,  0, -1,  0, -1,  0, -1, -1,  0,  0,\n","        0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,\n","        0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0, -1, -1,  0,  0, -1,\n","        0, -1,  0, -1,  0,  0, -1,  0,  0, -1,  0, -1, -1,  0,  0,  0, -1,\n","        0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1,  0,  0, -1,  0,  0,  0,\n","        0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0, -1,  0,\n","        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,\n","        0,  0,  0,  0, -1,  0,  0,  0, -1,  0, -1,  0,  0,  0,  0,  0,  0,\n","       -1,  0,  0, -1,  0, -1,  0,  0,  0,  0,  0, -1, -1,  0,  0,  0, -1,\n","        0,  0,  0, -1,  0,  0,  0,  0,  0,  0, -1,  0,  0, -1,  0,  0,  0,\n","       -1,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0, -1,  0,  0,  0,\n","       -1, -1,  0,  0,  0,  0, -1,  0,  0,  0,  0, -1,  0, -1, -1,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1,  0,  0,  0,  0,  0, -1,\n","        0,  0,  0, -1,  0,  0,  0, -1,  0, -1,  0,  0,  0, -1,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,\n","        0,  0,  0, -1,  0,  0, -1,  0,  0,  0,  0,  0,  0, -1, -1, -1,  0,\n","        0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0, -1,\n","        0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0, -1,\n","        0, -1,  0,  0, -1,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,\n","        0, -1,  0, -1,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0, -1,  0,\n","        0,  0, -1,  0,  0,  0, -1,  0,  0,  0, -1,  0,  0,  0,  0,  0, -1,\n","        0,  0,  0,  0,  0, -1, -1,  0,  0,  0, -1, -1,  0,  0, -1,  0,  0,\n","       -1,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0, -1,  0,  0,  0, -1,  0,\n","       -1,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0, -1,  0, -1,\n","        0,  0,  0,  0,  0,  0,  0, -1,  0,  0, -1,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0, -1,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0, -1,  0,  0,  0, -1,  0, -1,  0,  0, -1,  0,  0,  0,\n","        0,  0, -1,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0, -1,\n","        0, -1,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,\n","       -1,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0])"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7b5-j5F22oIn","executionInfo":{"status":"ok","timestamp":1678333189820,"user_tz":300,"elapsed":159,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"98e6ed7f-0868-4c5d-f6f5-98977470646b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n","       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n","       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n","       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n","       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n","       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n","       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n","       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n","       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n","       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n","       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n","       1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n","       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n","       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n","       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n","       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n","       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n","       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n","       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n","       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n","       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","       1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n","       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n","       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n","       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n","       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n","       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n","       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n","       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n","       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n","       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n","       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n","       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n","       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n","       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n","       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n","       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n","       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["correct=0\n","for y_pred,y_true in zip(cluster_labels,y):\n","  if abs(y_pred) == y_true:\n","    correct += 1\n","print(correct/len(y))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wlSo-bIl34Q8","executionInfo":{"status":"ok","timestamp":1678333201619,"user_tz":300,"elapsed":222,"user":{"displayName":"Monica Willson","userId":"18384632992554910821"}},"outputId":"d7b7a150-9cf4-435e-ffb6-c2a2f69b24eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.6576879910213244\n"]}]},{"cell_type":"markdown","source":["You can see HDBSCAN, even with the stock configurations, still beat k-means in terms of accuracy."],"metadata":{"id":"aSaq2vrF3rRc"}},{"cell_type":"markdown","source":["## Conclusion\n","So, in this tutorial you scratched the surface of one of the most popular clustering techniques - K-Means. You learned about its inner mechanics, implemented it using the Titanic Dataset in Python, and you also got a fair idea of its disadvantages. \n","\n","You can also check out a few other popular clustering methods [here](https://towardsdatascience.com/4-useful-clustering-methods-you-should-know-in-2021-ac61301e968e)."],"metadata":{"id":"ShlVVqwV1E74"}},{"cell_type":"code","metadata":{"id":"VrWN5f0f3GlE"},"source":["\n"],"execution_count":null,"outputs":[]}]}